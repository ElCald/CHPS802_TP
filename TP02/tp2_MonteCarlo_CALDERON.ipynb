{"cells":[{"cell_type":"markdown","metadata":{"id":"LvUYKP9Z6KHR"},"source":["# TP02"]},{"cell_type":"markdown","source":["## Installations"],"metadata":{"id":"HdoR_5bor_h8"}},{"cell_type":"markdown","metadata":{"id":"xPf-g7ni6Pio"},"source":["Installation de nvcc"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9454,"status":"ok","timestamp":1738410982794,"user":{"displayName":"Eliot","userId":"03339903271334990368"},"user_tz":-60},"id":"kRX9wNKq4U-W","outputId":"26e734dd-f472-4894-d017-2ad1690bd97f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.11.11\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Jun__6_02:18:23_PDT_2024\n","Cuda compilation tools, release 12.5, V12.5.82\n","Build cuda_12.5.r12.5/compiler.34385749_0\n","Collecting nvcc4jupyter\n","  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n","Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.1\n","Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmp5ig16_kw\".\n"]}],"source":["!python --version\n","!nvcc --version\n","!pip install nvcc4jupyter\n","%load_ext nvcc4jupyter"]},{"cell_type":"markdown","metadata":{"id":"MYBfTpdo5WZr"},"source":["Installation de Google Test"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZkzfOL2q5Y-w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738411001827,"user_tz":-60,"elapsed":19045,"user":{"displayName":"Eliot","userId":"03339903271334990368"}},"outputId":"c74be6e6-befb-4bd6-8fe7-0e6fadbc0c46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'googletest'...\n","remote: Enumerating objects: 27786, done.\u001b[K\n","remote: Counting objects: 100% (91/91), done.\u001b[K\n","remote: Compressing objects: 100% (66/66), done.\u001b[K\n","remote: Total 27786 (delta 51), reused 29 (delta 25), pack-reused 27695 (from 3)\u001b[K\n","Receiving objects: 100% (27786/27786), 13.30 MiB | 6.50 MiB/s, done.\n","Resolving deltas: 100% (20612/20612), done.\n","-- The C compiler identification is GNU 11.4.0\n","-- The CXX compiler identification is GNU 11.4.0\n","-- Detecting C compiler ABI info\n","-- Detecting C compiler ABI info - done\n","-- Check for working C compiler: /usr/bin/cc - skipped\n","-- Detecting C compile features\n","-- Detecting C compile features - done\n","-- Detecting CXX compiler ABI info\n","-- Detecting CXX compiler ABI info - done\n","-- Check for working CXX compiler: /usr/bin/c++ - skipped\n","-- Detecting CXX compile features\n","-- Detecting CXX compile features - done\n","-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n","-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n","-- Found Threads: TRUE\n","-- Configuring done (1.0s)\n","-- Generating done (0.0s)\n","-- Build files have been written to: /content/googletest/build\n","[ 12%] \u001b[32mBuilding CXX object googletest/CMakeFiles/gtest.dir/src/gtest-all.cc.o\u001b[0m\n","[ 25%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libgtest.a\u001b[0m\n","[ 25%] Built target gtest\n","[ 50%] \u001b[32mBuilding CXX object googlemock/CMakeFiles/gmock.dir/src/gmock-all.cc.o\u001b[0m\n","[ 50%] \u001b[32mBuilding CXX object googletest/CMakeFiles/gtest_main.dir/src/gtest_main.cc.o\u001b[0m\n","[ 62%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libgtest_main.a\u001b[0m\n","[ 62%] Built target gtest_main\n","[ 75%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libgmock.a\u001b[0m\n","[ 75%] Built target gmock\n","[ 87%] \u001b[32mBuilding CXX object googlemock/CMakeFiles/gmock_main.dir/src/gmock_main.cc.o\u001b[0m\n","[100%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libgmock_main.a\u001b[0m\n","[100%] Built target gmock_main\n"]}],"source":["!git clone https://github.com/google/googletest.git\n","!cd googletest && mkdir build && cd build && cmake .. && make -j$(nproc)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AqIusrGZOZHB","executionInfo":{"status":"ok","timestamp":1738411059529,"user_tz":-60,"elapsed":57714,"user":{"displayName":"Eliot","userId":"03339903271334990368"}},"outputId":"eedc917e-6ac2-4605-b266-3a8bf12cd392"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"eUmNJpAe5aWs"},"source":["-------------------"]},{"cell_type":"markdown","metadata":{"id":"EAZ2BPjF88rO"},"source":["## Makefile"]},{"cell_type":"code","execution_count":84,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":569,"status":"ok","timestamp":1738415973192,"user":{"displayName":"Eliot","userId":"03339903271334990368"},"user_tz":-60},"id":"-U4QzSbO896p","outputId":"db7c8464-8cc3-4985-bce4-6f4014202e10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting Makefile\n"]}],"source":["%%writefile Makefile\n","\n","INC\t:= -I$(CUDA_HOME)/include -I. -I../headers\n","LIB\t:= -L$(CUDA_HOME)/lib64 -lcudart -lcurand\n","GOOGLETEST := -Igoogletest/googletest/include -Lgoogletest/build/lib -lgtest -lgtest_main\n","\n","NVCCFLAGS\t:= -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math\n","\n","all:\tprac2_1 prac2_2 prac2_device prac2_average prac2_average_test\n","\n","\n","prac2_1:\tprac2_1.cu Makefile\n","\tnvcc prac2_1.cu -o prac2_1 $(INC) $(NVCCFLAGS) $(LIB)\n","\n","prac2_2:\tprac2_2.cu Makefile\n","\tnvcc prac2_2.cu -o prac2_2 $(INC) $(NVCCFLAGS) $(LIB)\n","\n","prac2_device:\tprac2_device.cu Makefile\n","\tnvcc prac2_device.cu -o prac2_device $(INC) $(NVCCFLAGS) $(LIB)\n","\n","prac2_average:\tprac2_average.cu Makefile\n","\tnvcc prac2_average.cu -o prac2_average $(INC) $(NVCCFLAGS) $(LIB)\n","\n","prac2_average_test:\tprac2_average_test.cu Makefile\n","\tnvcc $(GOOGLETEST) prac2_average_test.cu -o prac2_average_test $(INC) $(NVCCFLAGS) $(LIB)\n","\n","clean:\n","\trm -f prac2_1 prac2_2 prac2_device prac2_average prac2_average_test\n"]},{"cell_type":"markdown","metadata":{"id":"RMyPXFdA4129"},"source":["## Programmes"]},{"cell_type":"markdown","metadata":{"id":"DZC7o-Ut-hGY"},"source":["### Code 1\n","Découpage d'un tableau en mémoire cache <br>\n"]},{"cell_type":"markdown","source":["#### Version 1\n","`prac2_1.cu`"],"metadata":{"id":"i2CJyjL7rNXZ"}},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":830,"status":"ok","timestamp":1738416069898,"user":{"displayName":"Eliot","userId":"03339903271334990368"},"user_tz":-60},"id":"mtPKOko44y6f","outputId":"960f7372-e733-4aea-8098-140c4ac39c5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing prac2_1.cu\n"]}],"source":["%%writefile prac2_1.cu\n","\n","\n","//#include <gtest/gtest.h>\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <math.h>\n","\n","#include <cuda.h>\n","#include <curand.h>\n","#include \"/content/drive/MyDrive/Cours./s8/CHPS802 - GPU/TP/header/helper_cuda.h\"\n","\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// CUDA global constants\n","////////////////////////////////////////////////////////////////////////\n","\n","__constant__ int   N;\n","__constant__ float T, r, sigma, rho, alpha, dt, con1, con2;\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// kernel routine\n","////////////////////////////////////////////////////////////////////////\n","\n","\n","__global__ void pathcalc(float *d_z, float *d_v)\n","{\n","  float s1, s2, y1, y2, payoff;\n","  int   ind;\n","\n","  // move array pointers to correct position\n","\n","  // version 1\n","  ind = threadIdx.x + 2*N*blockIdx.x*blockDim.x;\n","\n","  // version 2\n","  //ind = 2*N*threadIdx.x + 2*N*blockIdx.x*blockDim.x;\n","\n","\n","  // path calculation\n","\n","  s1 = 1.0f;\n","  s2 = 1.0f;\n","\n","  for (int n=0; n<N; n++) {\n","    y1   = d_z[ind];\n","    // version 1\n","    ind += blockDim.x;      // shift pointer to next element\n","    // version 2\n","    //ind += 1;\n","\n","    y2   = rho*y1 + alpha*d_z[ind];\n","    // version 1\n","    ind += blockDim.x;      // shift pointer to next element\n","    // version 2\n","    //ind += 1;\n","\n","    s1 = s1*(con1 + con2*y1);\n","    s2 = s2*(con1 + con2*y2);\n","  }\n","\n","  // put payoff value into device array\n","\n","  payoff = 0.0f;\n","  if ( fabs(s1-1.0f)<0.1f && fabs(s2-1.0f)<0.1f ) payoff = exp(-r*T);\n","\n","  d_v[threadIdx.x + blockIdx.x*blockDim.x] = payoff;\n","}\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// Main program\n","////////////////////////////////////////////////////////////////////////\n","\n","int main(int argc, const char **argv){\n","\n","  int     NPATH=9600000, h_N=100;\n","  float   h_T, h_r, h_sigma, h_rho, h_alpha, h_dt, h_con1, h_con2;\n","  float  *h_v, *d_v, *d_z;\n","  double  sum1, sum2;\n","\n","  // initialise card\n","\n","  findCudaDevice(argc, argv);\n","\n","  // initialise CUDA timing\n","\n","  float milli;\n","  cudaEvent_t start, stop;\n","  cudaEventCreate(&start);\n","  cudaEventCreate(&stop);\n","\n","  // allocate memory on host and device\n","\n","  h_v = (float *)malloc(sizeof(float)*NPATH);\n","\n","  checkCudaErrors( cudaMalloc((void **)&d_v, sizeof(float)*NPATH) );\n","  checkCudaErrors( cudaMalloc((void **)&d_z, sizeof(float)*2*h_N*NPATH) );\n","\n","  // define constants and transfer to GPU\n","\n","  h_T     = 1.0f;\n","  h_r     = 0.05f;\n","  h_sigma = 0.1f;\n","  h_rho   = 0.5f;\n","  h_alpha = sqrt(1.0f-h_rho*h_rho);\n","  h_dt    = 1.0f/h_N;\n","  h_con1  = 1.0f + h_r*h_dt;\n","  h_con2  = sqrt(h_dt)*h_sigma;\n","\n","  checkCudaErrors( cudaMemcpyToSymbol(N,    &h_N,    sizeof(h_N)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(T,    &h_T,    sizeof(h_T)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(r,    &h_r,    sizeof(h_r)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(sigma,&h_sigma,sizeof(h_sigma)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(rho,  &h_rho,  sizeof(h_rho)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(alpha,&h_alpha,sizeof(h_alpha)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(dt,   &h_dt,   sizeof(h_dt)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(con1, &h_con1, sizeof(h_con1)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(con2, &h_con2, sizeof(h_con2)) );\n","\n","  // random number generation\n","\n","  curandGenerator_t gen;\n","  checkCudaErrors( curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT) );\n","  checkCudaErrors( curandSetPseudoRandomGeneratorSeed(gen, 1234ULL) );\n","\n","  cudaEventRecord(start);\n","  checkCudaErrors( curandGenerateNormal(gen, d_z, 2*h_N*NPATH, 0.0f, 1.0f) );\n","  cudaEventRecord(stop);\n","\n","  cudaEventSynchronize(stop);\n","  cudaEventElapsedTime(&milli, start, stop);\n","\n","  printf(\"CURAND normal RNG  execution time (ms): %f,  samples/sec: %e \\n\", milli, 2.0*h_N*NPATH/(0.001*milli));\n","\n","  // execute kernel and time it\n","\n","  cudaEventRecord(start);\n","  pathcalc<<<NPATH/128, 128>>>(d_z, d_v);\n","  cudaEventRecord(stop);\n","\n","  cudaEventSynchronize(stop);\n","  cudaEventElapsedTime(&milli, start, stop);\n","\n","  getLastCudaError(\"pathcalc execution failed\\n\");\n","  printf(\"Monte Carlo kernel execution time (ms): %f \\n\",milli);\n","\n","  // copy back results\n","\n","  checkCudaErrors( cudaMemcpy(h_v, d_v, sizeof(float)*NPATH,\n","                   cudaMemcpyDeviceToHost) );\n","\n","  // compute average\n","\n","  sum1 = 0.0;\n","  sum2 = 0.0;\n","  for (int i=0; i<NPATH; i++) {\n","    sum1 += h_v[i];\n","    sum2 += h_v[i]*h_v[i];\n","  }\n","\n","  printf(\"\\nAverage value and standard deviation of error  = %13.8f %13.8f\\n\\n\",\n","\t sum1/NPATH, sqrt((sum2/NPATH - (sum1/NPATH)*(sum1/NPATH))/NPATH) );\n","\n","  // Tidy up library\n","\n","  checkCudaErrors( curandDestroyGenerator(gen) );\n","\n","  // Release memory and exit cleanly\n","\n","  free(h_v);\n","  checkCudaErrors( cudaFree(d_v) );\n","  checkCudaErrors( cudaFree(d_z) );\n","\n","  // CUDA exit -- needed to flush printf write buffer\n","\n","  // Calcul du volume de données transférées\n","  double data_read = 2.0 * h_N * NPATH * sizeof(float) / 1e9; // en Go\n","  double data_written = NPATH * sizeof(float) / 1e9; // en Go\n","  double total_data = data_read + data_written;\n","\n","  // Calcul du taux de transfert effectif\n","  double execution_time = milli / 1000.0; // conversion en secondes\n","  double bandwidth = total_data / execution_time; // Go/s\n","\n","  printf(\"Data read: %f GB\\n\", data_read);\n","  printf(\"Data written: %f GB\\n\", data_written);\n","  printf(\"Total data transferred: %f GB\\n\", total_data);\n","  printf(\"Effective memory bandwidth: %f GB/s\\n\", bandwidth); // Environ 40GB/s avec le chargeur\n","\n","  cudaDeviceReset();\n","\n","\n","\n","}\n","\n","\n"]},{"cell_type":"markdown","source":["#### Version 2\n","`prac2_2.cu`"],"metadata":{"id":"5wfvDWQGqukm"}},{"cell_type":"code","source":["%%writefile prac2_2.cu\n","\n","\n","//#include <gtest/gtest.h>\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <math.h>\n","\n","#include <cuda.h>\n","#include <curand.h>\n","#include \"/content/drive/MyDrive/Cours./s8/CHPS802 - GPU/TP/header/helper_cuda.h\"\n","\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// CUDA global constants\n","////////////////////////////////////////////////////////////////////////\n","\n","__constant__ int   N;\n","__constant__ float T, r, sigma, rho, alpha, dt, con1, con2;\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// kernel routine\n","////////////////////////////////////////////////////////////////////////\n","\n","\n","__global__ void pathcalc(float *d_z, float *d_v)\n","{\n","  float s1, s2, y1, y2, payoff;\n","  int   ind;\n","\n","  // move array pointers to correct position\n","\n","  // version 1\n","  //ind = threadIdx.x + 2*N*blockIdx.x*blockDim.x;\n","\n","  // version 2\n","  ind = 2*N*threadIdx.x + 2*N*blockIdx.x*blockDim.x;\n","\n","\n","  // path calculation\n","\n","  s1 = 1.0f;\n","  s2 = 1.0f;\n","\n","  for (int n=0; n<N; n++) {\n","    y1   = d_z[ind];\n","    // version 1\n","    //ind += blockDim.x;      // shift pointer to next element\n","    // version 2\n","    ind += 1;\n","\n","    y2   = rho*y1 + alpha*d_z[ind];\n","    // version 1\n","    //ind += blockDim.x;      // shift pointer to next element\n","    // version 2\n","    ind += 1;\n","\n","    s1 = s1*(con1 + con2*y1);\n","    s2 = s2*(con1 + con2*y2);\n","  }\n","\n","  // put payoff value into device array\n","\n","  payoff = 0.0f;\n","  if ( fabs(s1-1.0f)<0.1f && fabs(s2-1.0f)<0.1f ) payoff = exp(-r*T);\n","\n","  d_v[threadIdx.x + blockIdx.x*blockDim.x] = payoff;\n","}\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// Main program\n","////////////////////////////////////////////////////////////////////////\n","\n","int main(int argc, const char **argv){\n","\n","  int     NPATH=9600000, h_N=100;\n","  float   h_T, h_r, h_sigma, h_rho, h_alpha, h_dt, h_con1, h_con2;\n","  float  *h_v, *d_v, *d_z;\n","  double  sum1, sum2;\n","\n","  // initialise card\n","\n","  findCudaDevice(argc, argv);\n","\n","  // initialise CUDA timing\n","\n","  float milli;\n","  cudaEvent_t start, stop;\n","  cudaEventCreate(&start);\n","  cudaEventCreate(&stop);\n","\n","  // allocate memory on host and device\n","\n","  h_v = (float *)malloc(sizeof(float)*NPATH);\n","\n","  checkCudaErrors( cudaMalloc((void **)&d_v, sizeof(float)*NPATH) );\n","  checkCudaErrors( cudaMalloc((void **)&d_z, sizeof(float)*2*h_N*NPATH) );\n","\n","  // define constants and transfer to GPU\n","\n","  h_T     = 1.0f;\n","  h_r     = 0.05f;\n","  h_sigma = 0.1f;\n","  h_rho   = 0.5f;\n","  h_alpha = sqrt(1.0f-h_rho*h_rho);\n","  h_dt    = 1.0f/h_N;\n","  h_con1  = 1.0f + h_r*h_dt;\n","  h_con2  = sqrt(h_dt)*h_sigma;\n","\n","  checkCudaErrors( cudaMemcpyToSymbol(N,    &h_N,    sizeof(h_N)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(T,    &h_T,    sizeof(h_T)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(r,    &h_r,    sizeof(h_r)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(sigma,&h_sigma,sizeof(h_sigma)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(rho,  &h_rho,  sizeof(h_rho)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(alpha,&h_alpha,sizeof(h_alpha)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(dt,   &h_dt,   sizeof(h_dt)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(con1, &h_con1, sizeof(h_con1)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(con2, &h_con2, sizeof(h_con2)) );\n","\n","  // random number generation\n","\n","  curandGenerator_t gen;\n","  checkCudaErrors( curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT) );\n","  checkCudaErrors( curandSetPseudoRandomGeneratorSeed(gen, 1234ULL) );\n","\n","  cudaEventRecord(start);\n","  checkCudaErrors( curandGenerateNormal(gen, d_z, 2*h_N*NPATH, 0.0f, 1.0f) );\n","  cudaEventRecord(stop);\n","\n","  cudaEventSynchronize(stop);\n","  cudaEventElapsedTime(&milli, start, stop);\n","\n","  printf(\"CURAND normal RNG  execution time (ms): %f,  samples/sec: %e \\n\", milli, 2.0*h_N*NPATH/(0.001*milli));\n","\n","  // execute kernel and time it\n","\n","  cudaEventRecord(start);\n","  pathcalc<<<NPATH/128, 128>>>(d_z, d_v);\n","  cudaEventRecord(stop);\n","\n","  cudaEventSynchronize(stop);\n","  cudaEventElapsedTime(&milli, start, stop);\n","\n","  getLastCudaError(\"pathcalc execution failed\\n\");\n","  printf(\"Monte Carlo kernel execution time (ms): %f \\n\",milli);\n","\n","  // copy back results\n","\n","  checkCudaErrors( cudaMemcpy(h_v, d_v, sizeof(float)*NPATH,\n","                   cudaMemcpyDeviceToHost) );\n","\n","  // compute average\n","\n","  sum1 = 0.0;\n","  sum2 = 0.0;\n","  for (int i=0; i<NPATH; i++) {\n","    sum1 += h_v[i];\n","    sum2 += h_v[i]*h_v[i];\n","  }\n","\n","  printf(\"\\nAverage value and standard deviation of error  = %13.8f %13.8f\\n\\n\",\n","\t sum1/NPATH, sqrt((sum2/NPATH - (sum1/NPATH)*(sum1/NPATH))/NPATH) );\n","\n","  // Tidy up library\n","\n","  checkCudaErrors( curandDestroyGenerator(gen) );\n","\n","  // Release memory and exit cleanly\n","\n","  free(h_v);\n","  checkCudaErrors( cudaFree(d_v) );\n","  checkCudaErrors( cudaFree(d_z) );\n","\n","  // CUDA exit -- needed to flush printf write buffer\n","\n","  // Calcul du volume de données transférées\n","  double data_read = 2.0 * h_N * NPATH * sizeof(float) / 1e9; // en Go\n","  double data_written = NPATH * sizeof(float) / 1e9; // en Go\n","  double total_data = data_read + data_written;\n","\n","  // Calcul du taux de transfert effectif\n","  double execution_time = milli / 1000.0; // conversion en secondes\n","  double bandwidth = total_data / execution_time; // Go/s\n","\n","  printf(\"Data read: %f GB\\n\", data_read);\n","  printf(\"Data written: %f GB\\n\", data_written);\n","  printf(\"Total data transferred: %f GB\\n\", total_data);\n","  printf(\"Effective memory bandwidth: %f GB/s\\n\", bandwidth); // Environ 40GB/s avec le chargeur\n","\n","  cudaDeviceReset();\n","\n","\n","\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nYISOhPjqwSh","executionInfo":{"status":"ok","timestamp":1738416054599,"user_tz":-60,"elapsed":688,"user":{"displayName":"Eliot","userId":"03339903271334990368"}},"outputId":"0c4dd940-2c40-4da2-c260-7c32a78a9e39"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing prac2_2.cu\n"]}]},{"cell_type":"markdown","metadata":{"id":"vlO0pHJR-bOd"},"source":["### Code 2\n"]},{"cell_type":"markdown","source":["`prac2_device.cu`"],"metadata":{"id":"Uvxotl_otASv"}},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":422,"status":"ok","timestamp":1738416153818,"user":{"displayName":"Eliot","userId":"03339903271334990368"},"user_tz":-60},"id":"6GISFFtr9vwp","outputId":"97fa5336-f110-49b1-f739-a25e72f52dcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing prac2_device.cu\n"]}],"source":["%%writefile prac2_device.cu\n","\n","////////////////////////////////////////////////////////////////////////\n","// GPU version of Monte Carlo algorithm using NVIDIA's CURAND library\n","////////////////////////////////////////////////////////////////////////\n","\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include <math.h>\n","\n","#include <cuda.h>\n","#include <curand_kernel.h>\n","\n","#include \"/content/drive/MyDrive/Cours./s8/CHPS802 - GPU/TP/header/helper_cuda.h\"\n","\n","////////////////////////////////////////////////////////////////////////\n","// CUDA global constants\n","////////////////////////////////////////////////////////////////////////\n","\n","__constant__ int   N;\n","__constant__ float T, r, sigma, rho, alpha, dt, con1, con2;\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// kernel routines -- see sections 3.5, 3.6 in cuRAND documentation\n","////////////////////////////////////////////////////////////////////////\n","\n","__global__ void RNG_init(curandState *state)\n","{\n","  // RNG initialisation with id-based skipahead\n","  int id = threadIdx.x + blockIdx.x*blockDim.x;\n","  curand_init(1234, id, 0, &state[id]);\n","}\n","\n","\n","__global__ void pathcalc(curandState *device_state, float *d_v,\n","                         int mpath, int NPATH)\n","{\n","  float s1, s2, y1, y2, payoff;\n","\n","  int id = threadIdx.x + blockIdx.x*blockDim.x;\n","  curandState_t state = device_state[id];\n","\n","  for(int m=0; m<mpath; m++) {\n","    s1 = 1.0f;\n","    s2 = 1.0f;\n","\n","    for (int n=0; n<N; n++) {\n","      y1 = curand_normal(&state);\n","      y2 = rho*y1 + alpha*curand_normal(&state);\n","\n","      s1 = s1*(con1 + con2*y1);\n","      s2 = s2*(con1 + con2*y2);\n","    }\n","\n","    // put payoff value into device array\n","\n","    payoff = 0.0f;\n","    if ( fabs(s1-1.0f)<0.1f && fabs(s2-1.0f)<0.1f ) payoff = exp(-r*T);\n","\n","    int payoff_id = id + m*gridDim.x*blockDim.x;\n","    if (payoff_id < NPATH) d_v[payoff_id] = payoff;\n","  }\n","}\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// Main program\n","////////////////////////////////////////////////////////////////////////\n","\n","int main(int argc, const char **argv){\n","\n","  int     NPATH=9600000, h_N=100;\n","  float   h_T, h_r, h_sigma, h_rho, h_alpha, h_dt, h_con1, h_con2;\n","  float  *h_v, *d_v;\n","  double  sum1, sum2;\n","  curandState *state;\n","\n","  // initialise card\n","\n","  findCudaDevice(argc, argv);\n","\n","  // initialise CUDA timing\n","\n","  float milli;\n","  cudaEvent_t start, stop;\n","  cudaEventCreate(&start);\n","  cudaEventCreate(&stop);\n","\n","  // allocate memory on host and device\n","\n","  h_v = (float *)malloc(sizeof(float)*NPATH);\n","  checkCudaErrors( cudaMalloc((void **)&d_v, sizeof(float)*NPATH) );\n","  checkCudaErrors( cudaMalloc((void **)&state, sizeof(curandState)*NPATH) );\n","\n","  printf(\"size of curandState is %lu bytes\\n\",sizeof(curandState));\n","\n","  // define constants and transfer to GPU\n","\n","  h_T     = 1.0f;\n","  h_r     = 0.05f;\n","  h_sigma = 0.1f;\n","  h_rho   = 0.5f;\n","  h_alpha = sqrt(1.0f-h_rho*h_rho);\n","  h_dt    = 1.0f/h_N;\n","  h_con1  = 1.0f + h_r*h_dt;\n","  h_con2  = sqrt(h_dt)*h_sigma;\n","\n","  checkCudaErrors( cudaMemcpyToSymbol(N,    &h_N,    sizeof(h_N)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(T,    &h_T,    sizeof(h_T)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(r,    &h_r,    sizeof(h_r)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(sigma,&h_sigma,sizeof(h_sigma)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(rho,  &h_rho,  sizeof(h_rho)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(alpha,&h_alpha,sizeof(h_alpha)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(dt,   &h_dt,   sizeof(h_dt)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(con1, &h_con1, sizeof(h_con1)) );\n","  checkCudaErrors( cudaMemcpyToSymbol(con2, &h_con2, sizeof(h_con2)) );\n","\n","  // calculate theoretical occupancy -- see Pro Tip blog article:\n","  // https://developer.nvidia.com/blog/cuda-pro-tip-occupancy-api-simplifies-launch-configuration/\n","\n","  int device;\n","  cudaDeviceProp props;\n","  cudaGetDevice(&device);\n","  cudaGetDeviceProperties(&props, device);\n","\n","  int maxActiveBlocks, blockSize=128;\n","  cudaOccupancyMaxActiveBlocksPerMultiprocessor( &maxActiveBlocks, pathcalc, blockSize, 0);\n","  printf(\"maxActiveBlocks/SM = %d \\n\",maxActiveBlocks);\n","  printf(\"number of SMs      = %d \\n\",props.multiProcessorCount);\n","  int blocks = maxActiveBlocks*props.multiProcessorCount;\n","\n","  // execute kernels\n","\n","  cudaEventRecord(start);\n","  RNG_init<<<blocks, 128>>>(state);\n","  cudaEventRecord(stop);\n","\n","  cudaEventSynchronize(stop);\n","  cudaEventElapsedTime(&milli, start, stop);\n","\n","  getLastCudaError(\"RNG_init execution failed\\n\");\n","  printf(\"RNG_init kernel execution time (ms): %f \\n\",milli);\n","\n","  int paths_per_thread = (NPATH-1)/(128*blocks) + 1;\n","  cudaEventRecord(start);\n","  pathcalc<<<blocks, 128>>>(state,d_v,paths_per_thread,NPATH);\n","  cudaEventRecord(stop);\n","\n","  cudaEventSynchronize(stop);\n","  cudaEventElapsedTime(&milli, start, stop);\n","\n","  getLastCudaError(\"pathcalc execution failed\\n\");\n","  printf(\"pathcalc kernel execution time (ms): %f \\n\",milli);\n","\n","  // copy back results\n","\n","  checkCudaErrors( cudaMemcpy(h_v, d_v, sizeof(float)*NPATH,\n","                   cudaMemcpyDeviceToHost) );\n","\n","  // compute average\n","\n","  sum1 = 0.0;\n","  sum2 = 0.0;\n","  for (int i=0; i<NPATH; i++) {\n","    sum1 += h_v[i];\n","    sum2 += h_v[i]*h_v[i];\n","  }\n","\n","  printf(\"\\nAverage value and standard deviation of error  = %13.8f %13.8f\\n\\n\",\n","\t sum1/NPATH, sqrt((sum2/NPATH - (sum1/NPATH)*(sum1/NPATH))/NPATH) );\n","\n","  // Release memory and exit cleanly\n","\n","  free(h_v);\n","  checkCudaErrors( cudaFree(d_v) );\n","\n","  // CUDA exit -- needed to flush printf write buffer\n","\n","  cudaDeviceReset();\n","\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"Gg8tlpCl5_nI"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KDzEqP_AwLTF"},"source":["### Code 3\n","\n","Calcule de az^2 + bz +c"]},{"cell_type":"markdown","source":["#### Version normal\n","`prac2_average.cu`"],"metadata":{"id":"xVTUYmu3sFqH"}},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":712,"status":"ok","timestamp":1738416158341,"user":{"displayName":"Eliot","userId":"03339903271334990368"},"user_tz":-60},"id":"iXvAl9CEwHLc","outputId":"1fa08096-1dc1-4ba7-cde6-ff5bcbe36353"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting prac2_average.cu\n"]}],"source":["%%writefile prac2_average.cu\n","\n","\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <math.h>\n","\n","#include <cuda.h>\n","#include <curand.h>\n","#include <curand_kernel.h>\n","#include \"/content/drive/MyDrive/Cours./s8/CHPS802 - GPU/TP/header/helper_cuda.h\"\n","\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// CUDA global constants\n","////////////////////////////////////////////////////////////////////////\n","\n","__constant__ float  a=20.0f, b=25.0f, c=15.0f;\n","\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// kernel routine\n","////////////////////////////////////////////////////////////////////////\n","\n","__global__ void kernel_gen_rand_nums(unsigned long seed, float *d_tab, int nb_val)\n","{\n","    curandState state;\n","    curand_init(seed, threadIdx.x, 0, &state);\n","\n","    int tid = threadIdx.x + blockDim.x*blockIdx.x;\n","    double z, som=0;\n","\n","\n","    for(int i =0; i<nb_val; i++){\n","      z = curand_normal(&state);  // Génère un nombre aléatoire entre 0 et 1\n","      som += (a*pow(z,2.0) + b * z + c);\n","    }\n","\n","    d_tab[tid] = som/nb_val;\n","\n","}\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// Main program\n","////////////////////////////////////////////////////////////////////////\n","\n","int main(int argc, const char **argv){\n","\n","  // variables\n","  float *d_tab, *h_tab; // tableau contenant la valeur générée par chaque thread\n","  int d_size_tab; // Taille du tableau\n","  int nb_val;             // Nombre de valeurs générées par thread\n","  int nb_blocks, nb_threads; // Nombre de blocs et nombre de threads\n","  float som_total=0, moyenne=0;\n","  const float d_a=20.0f, d_c=15.0f;\n","\n","  curandState *devStates; // Etat du générateur\n","\n","\n","  // init size blocks / threads / tab\n","  nb_blocks = 128;\n","  nb_threads = 128;\n","  d_size_tab = nb_blocks * nb_threads;\n","  nb_val = 200;\n","\n","\n","  // Allocation\n","  cudaMalloc((void**)&devStates, nb_threads * sizeof(curandState));\n","  checkCudaErrors(cudaMallocManaged(&d_tab, d_size_tab*sizeof(float)));\n","  h_tab = (float*)malloc(sizeof(float) * d_size_tab);\n","\n","\n","\n","  // execute kernel\n","\n","  kernel_gen_rand_nums<<<nb_blocks, nb_threads>>>(time(NULL), d_tab, nb_val);\n","\n","  cudaDeviceSynchronize();\n","\n","\n","  // Copy device 2 host\n","  checkCudaErrors( cudaMemcpy(h_tab, d_tab, sizeof(float)*d_size_tab, cudaMemcpyDeviceToHost) );\n","\n","\n","  // Calcul moyenne\n","\n","  for(int i=0; i<d_size_tab; i++){\n","    som_total += h_tab[i];\n","  }\n","\n","  moyenne = som_total / d_size_tab;\n","\n","  printf(\"Moyenne: %lf\\n\", moyenne);\n","  printf(\"a + c: %lf\\n\", d_a+d_c);\n","\n","\n","\n","\n","  // Libération de la mémoire\n","  free(h_tab);\n","  checkCudaErrors( cudaFree(d_tab) );\n","  checkCudaErrors( cudaFree(devStates) );\n","\n","\n","  // CUDA exit -- needed to flush printf write buffer\n","  cudaDeviceReset();\n","\n","}"]},{"cell_type":"markdown","source":["#### Version test unitaire\n","`prac2_average_test.cu`"],"metadata":{"id":"IbQ1KwWxX1I3"}},{"cell_type":"code","source":["%%writefile prac2_average_test.cu\n","\n","#include <gtest/gtest.h>\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <math.h>\n","\n","#include <cuda.h>\n","#include <curand.h>\n","#include <curand_kernel.h>\n","#include \"/content/drive/MyDrive/Cours./s8/CHPS802 - GPU/TP/header/helper_cuda.h\"\n","\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// CUDA global constants\n","////////////////////////////////////////////////////////////////////////\n","\n","__constant__ float  a=258.4f, b=27.05f, c=451.358f;\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// kernel routine\n","////////////////////////////////////////////////////////////////////////\n","\n","\n","\n","__global__ void kernel_gen_rand_nums(unsigned long seed, float *d_tab, int nb_val)\n","{\n","    curandState state;\n","    curand_init(seed, threadIdx.x, 0, &state);\n","\n","    int tid = threadIdx.x + blockDim.x*blockIdx.x;\n","    double z, som=0;\n","\n","\n","    for(int i =0; i<nb_val; i++){\n","      z = curand_normal(&state);  // Génère un nombre aléatoire entre 0 et 1\n","      som += (a*pow(z,2.0) + b * z + c);\n","    }\n","\n","    d_tab[tid] = som/nb_val;\n","\n","}\n","\n","\n","////////////////////////////////////////////////////////////////////////\n","// Main program\n","////////////////////////////////////////////////////////////////////////\n","\n","TEST(CudaTest, CalculMoyenne) {\n","  // variables\n","  float *d_tab, *h_tab; // tableau contenant la valeur générée par chaque thread\n","  int d_size_tab; // Taille du tableau\n","  int nb_val;             // Nombre de valeurs générées par thread\n","  int nb_blocks, nb_threads; // Nombre de blocs et nombre de threads\n","  float som_total=0, moyenne=0;\n","  const float d_a=258.4f, d_c=451.358f;\n","\n","  curandState *devStates; // Etat du générateur\n","\n","\n","  // init size blocks / threads / tab\n","  nb_blocks = 128;\n","  nb_threads = 128;\n","  d_size_tab = nb_blocks * nb_threads;\n","  nb_val = 200;\n","\n","\n","  // Allocation\n","  cudaMalloc((void**)&devStates, nb_threads * sizeof(curandState));\n","  checkCudaErrors(cudaMallocManaged(&d_tab, d_size_tab*sizeof(float)));\n","  h_tab = (float*)malloc(sizeof(float) * d_size_tab);\n","\n","\n","\n","  // execute kernel\n","\n","  kernel_gen_rand_nums<<<nb_blocks, nb_threads>>>(time(NULL), d_tab, nb_val);\n","\n","  cudaDeviceSynchronize();\n","\n","\n","  // Copy device 2 host\n","  checkCudaErrors( cudaMemcpy(h_tab, d_tab, sizeof(float)*d_size_tab, cudaMemcpyDeviceToHost) );\n","\n","\n","  // Calcul moyenne\n","\n","  for(int i=0; i<d_size_tab; i++){\n","    som_total += h_tab[i];\n","  }\n","\n","  moyenne = som_total / d_size_tab;\n","\n","  printf(\"Moyenne: %lf\\n\", moyenne);\n","  printf(\"a + c: %lf\\n\", d_a+d_c);\n","\n","  // Test si la moyenne obtenue est bien environ égale à A + C avec une marge d'erreur de 1.5\n","  EXPECT_NEAR(moyenne, d_a+d_c, 1.5);\n","\n","\n","  // Libération de la mémoire\n","  free(h_tab);\n","  checkCudaErrors( cudaFree(d_tab) );\n","  checkCudaErrors( cudaFree(devStates) );\n","\n","\n","  // CUDA exit -- needed to flush printf write buffer\n","  cudaDeviceReset();\n","\n","}\n","\n","int main(int argc, char **argv) {\n","    ::testing::InitGoogleTest(&argc, argv);\n","    return RUN_ALL_TESTS();\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QsGTeV6DX0ur","executionInfo":{"status":"ok","timestamp":1738416159102,"user_tz":-60,"elapsed":9,"user":{"displayName":"Eliot","userId":"03339903271334990368"}},"outputId":"1ee35a4b-5a8d-4c8d-b6e7-2e85ef858785"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting prac2_average_test.cu\n"]}]},{"cell_type":"markdown","metadata":{"id":"NUjVdDA65nJK"},"source":["## Compilation & exécution"]},{"cell_type":"markdown","metadata":{"id":"fspYpyc_43Eb"},"source":["### Compilation cuda"]},{"cell_type":"code","execution_count":91,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FvgEkEtJ9Dj_","outputId":"221ee577-05d1-4f17-adf5-b5dc3c0eccbb","executionInfo":{"status":"ok","timestamp":1738416176993,"user_tz":-60,"elapsed":15084,"user":{"displayName":"Eliot","userId":"03339903271334990368"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc prac2_device.cu -o prac2_device -I/include -I. -I../headers -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -L/lib64 -lcudart -lcurand\n","ptxas info    : 218048 bytes gmem, 108 bytes cmem[3], 64 bytes cmem[4]\n","ptxas info    : Compiling entry function '_Z8pathcalcP17curandStateXORWOWPfii' for 'sm_70'\n","ptxas info    : Function properties for _Z8pathcalcP17curandStateXORWOWPfii\n","    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","ptxas info    : Used 29 registers, 376 bytes cmem[0]\n","ptxas info    : Compiling entry function '_Z8RNG_initP17curandStateXORWOW' for 'sm_70'\n","ptxas info    : Function properties for _Z8RNG_initP17curandStateXORWOW\n","    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","ptxas info    : Used 32 registers, 360 bytes cmem[0]\n","nvcc prac2_average.cu -o prac2_average -I/include -I. -I../headers -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -L/lib64 -lcudart -lcurand\n","ptxas info    : 218048 bytes gmem, 84 bytes cmem[3], 64 bytes cmem[4]\n","ptxas info    : Compiling entry function '_Z20kernel_gen_rand_numsmPfi' for 'sm_70'\n","ptxas info    : Function properties for _Z20kernel_gen_rand_numsmPfi\n","    48 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","ptxas info    : Used 42 registers, 48 bytes cumulative stack size, 372 bytes cmem[0], 184 bytes cmem[2]\n","ptxas info    : Function properties for __internal_accurate_pow\n","    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","nvcc -Igoogletest/googletest/include -Lgoogletest/build/lib -lgtest -lgtest_main prac2_average_test.cu -o prac2_average_test -I/include -I. -I../headers -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -L/lib64 -lcudart -lcurand\n","ptxas info    : 218048 bytes gmem, 84 bytes cmem[3], 64 bytes cmem[4]\n","ptxas info    : Compiling entry function '_Z20kernel_gen_rand_numsmPfi' for 'sm_70'\n","ptxas info    : Function properties for _Z20kernel_gen_rand_numsmPfi\n","    48 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n","ptxas info    : Used 42 registers, 48 bytes cumulative stack size, 372 bytes cmem[0], 184 bytes cmem[2]\n","ptxas info    : Function properties for __internal_accurate_pow\n","    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n"]}],"source":["!make"]},{"cell_type":"markdown","metadata":{"id":"pHaLu-9I467I"},"source":["### Execution"]},{"cell_type":"code","execution_count":92,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":895,"status":"ok","timestamp":1738416188774,"user":{"displayName":"Eliot","userId":"03339903271334990368"},"user_tz":-60},"id":"wggXawy948YG","outputId":"76e6a739-9057-47b3-c9df-6e5eaa624de9"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Device 0: \"Turing\" with compute capability 7.5\n","\n","CURAND normal RNG  execution time (ms): 166.990341,  samples/sec: 1.149767e+10 \n","Monte Carlo kernel execution time (ms): 29.559776 \n","\n","Average value and standard deviation of error  =    0.41786269    0.00015237\n","\n","Data read: 7.680000 GB\n","Data written: 0.038400 GB\n","Total data transferred: 7.718400 GB\n","Effective memory bandwidth: 261.111584 GB/s\n"]}],"source":["# Version 1\n","!./prac2_1"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1532,"status":"ok","timestamp":1738416194132,"user":{"displayName":"Eliot","userId":"03339903271334990368"},"user_tz":-60},"id":"w7_axULUAPk9","outputId":"e1d1f809-aa44-4271-95df-9f184292b1b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Device 0: \"Turing\" with compute capability 7.5\n","\n","CURAND normal RNG  execution time (ms): 107.004028,  samples/sec: 1.794325e+10 \n","Monte Carlo kernel execution time (ms): 90.240799 \n","\n","Average value and standard deviation of error  =    0.41793859    0.00015237\n","\n","Data read: 7.680000 GB\n","Data written: 0.038400 GB\n","Total data transferred: 7.718400 GB\n","Effective memory bandwidth: 85.531158 GB/s\n"]}],"source":["# Version 2\n","!./prac2_2"]},{"cell_type":"markdown","metadata":{"id":"oWF9p3iZI-qZ"},"source":["On remarque qu'avec la version 2, c'est bien plus lent et celà est du aux accès mémoires. <br>\n","Dans la 1ère version on charge dans la longueur du cache tout le tableau. <br>\n","Dans la 2ème version on charge une case sur deux donc le tableau complet n'est pas chargé à la suite ce qui fait qu'on n'a pas cette capacité de mémoire contigue.\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1435,"status":"ok","timestamp":1738170442233,"user":{"displayName":"Eliot","userId":"03339903271334990368"},"user_tz":-60},"id":"GagaEvf0A0J_","outputId":"354b03c2-6aa8-4c0f-9b31-aa846cea4cdc"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU Device 0: \"Turing\" with compute capability 7.5\n","\n","size of curandState is 48 bytes\n","maxActiveBlocks/SM = 8 \n","number of SMs      = 40 \n","RNG_init kernel execution time (ms): 1.703936 \n","pathcalc kernel execution time (ms): 23.821184 \n","\n","Average value and standard deviation of error  =    0.41802440    0.00015237\n","\n"]}],"source":["!./prac2_device"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"OPrdxBn-r6M1"}},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":679,"status":"ok","timestamp":1738415801697,"user":{"displayName":"Eliot","userId":"03339903271334990368"},"user_tz":-60},"id":"qSZFmv69s6_i","outputId":"f274280f-cfd5-47b9-ba82-f293c878a8c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Moyenne: 34.968338\n","a + c: 35.000000\n"]}],"source":["!./prac2_average"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"4KFUvVFACUZD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738415694742,"user_tz":-60,"elapsed":9,"user":{"displayName":"Eliot","userId":"03339903271334990368"}},"outputId":"136d06f1-309d-4632-85ba-c0f704699a77"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0;32m[==========] \u001b[mRunning 1 test from 1 test suite.\n","\u001b[0;32m[----------] \u001b[mGlobal test environment set-up.\n","\u001b[0;32m[----------] \u001b[m1 test from CudaTest\n","\u001b[0;32m[ RUN      ] \u001b[mCudaTest.CalculMoyenne\n","Moyenne: 710.186951\n","a + c: 709.757996\n","\u001b[0;32m[       OK ] \u001b[mCudaTest.CalculMoyenne (143 ms)\n","\u001b[0;32m[----------] \u001b[m1 test from CudaTest (143 ms total)\n","\n","\u001b[0;32m[----------] \u001b[mGlobal test environment tear-down\n","\u001b[0;32m[==========] \u001b[m1 test from 1 test suite ran. (143 ms total)\n","\u001b[0;32m[  PASSED  ] \u001b[m1 test.\n"]}],"source":["!./prac2_average_test"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["DZC7o-Ut-hGY","vlO0pHJR-bOd"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}